# 查重系统逻辑设计方案 (Duplication Check Logic Design) v2.0

**目标**: 针对新上传的商业案例 PDF，在已建立的 SQLite 知识库（包含5年历史数据）中，找出所有重复或高度相似的内容。
**核心原则**: **宁滥勿缺 (High Recall)** + **分级预警 (Graded Alert)**。
**验证策略**: **分赛道隔离 (Track Isolation)** —— 理论与知识点互不混淆。

---

## 核心流程架构

整个查重过程分为四个阶段：
1. **新文件画像 (Profiling)**: 使用与建库时一致的标准，提取新文件的“理论”与“知识点”。
2. **分赛道匹配 (Isolated Matching)**: 将“新理论”与“库中理论”比对，“新知识点”与“库中知识点”比对。
3. **AI 裁判打分 (AI Judging)**: **(核心升级)** AI 不仅判断“是否相关”，还必须给出“相关度等级”（High/Medium/Low）。
4. **全景报表 (Reporting)**: 生成包含双 Sheet 的 Excel，按相关度降序排列。

---

## 详细步骤说明

### 阶段一：新文件提取 (Extraction)
*   **输入**: 新上传的 PDF 文件。
*   **动作**: 调用 Gemini API 读取全文。
*   **提取策略**: 
    *   强制区分 `category`：如果是模棱两可的概念，在 JSON 中同时生成两条记录（一条理论，一条知识点）。
    *   保留 `context`：新文件的每一条提取记录，都必须带上原文语境。
*   **输出**: 
    ```json
    {
      "theories": ["新理论A", "新理论B"],
      "points": ["新知识点1", "新知识点2"]
    }
    ```

### 阶段二：分赛道匹配 (Isolated Matching)

为了避免将“SWOT分析法”（理论）与“SWOT分析应用”（知识点）混在一起导致报表混乱，我们设立两条独立的流水线：

#### 赛道 A：理论查重 (Theory Track)
*   **选手**: 新文件提取出的所有 `category="理论"` 的词。
*   **对手**: 数据库中所有 `category="理论"` 的去重标签 (`SELECT DISTINCT standard_name FROM knowledge_points WHERE category='理论'`)。
*   **机制**: 仅在“理论池”中寻找相似项。

#### 赛道 B：知识点查重 (Knowledge Point Track)
*   **选手**: 新文件提取出的所有 `category="知识点"` 的词。
*   **对手**: 数据库中所有 `category="知识点"` 的标签。
*   **机制**: 仅在“知识点池”中寻找相似项。

### 阶段三：AI 裁判打分 (AI Judging) —— *The "No Omission" Engine*

我们将“新词列表”和“旧词列表”同时发给 AI，要求 AI 必须按照以下标准输出匹配关系：

| 等级 (Relevance) | 定义 (Definition) | 例子 (Example) | 处理策略 |
| :--- | :--- | :--- | :--- |
| **High (最相关)** | 完全同义、翻译差异、缩写互换 | "KOL" vs "关键意见领袖"<br>"长尾效应" vs "长尾理论" | **红色预警**，极大概率重复 |
| **Medium (次相关)** | 包含关系、强依赖、应用变体 | "私域流量" vs "用户留存"<br>"O2O模式" vs "线上线下融合" | **黄色预警**，需人工核对语境 |
| **Low (相关)** | 同一大领域、弱关联 | "人工智能" vs "机器学习"<br>"短视频" vs "直播带货" | **绿色提示**，作为参考背景 |

**Prompt 指令核心**:
> "Check every new term against the DB list. If there is ANY connection, output it. Better to flag a 'Low' match than to miss a potential link." (宁滥勿缺，哪怕是弱相关也要报出来)

### 阶段四：证据回溯与报表 (Evidence & Reporting)

系统将生成一个包含两个 Sheet 的 Excel 文件：

#### Sheet 1: 理论查重
*   **排序**: 按 `相关度` 降序 (High -> Medium -> Low)。
*   **列结构**:
    1.  **相关度** (High/Medium/Low)
    2.  **新理论名称** (e.g., "破坏性创新")
    3.  **新文件语境** ("本文利用破坏性创新理论分析了...")
    4.  **匹配到的库中理论** (e.g., "颠覆性创新")
    5.  **历史来源文件** (e.g., "FDC-23-某公司.pdf")
    6.  **历史年份** (2023)
    7.  **历史语境证据** ("该公司是颠覆性创新的典型代表...")

#### Sheet 2: 知识点查重
*   结构同上，但内容为实务概念（如“数字化转型”、“降本增效”）。

---

## 方案优势

1.  **精确性与广度的平衡**: 通过分级 (High/Medium/Low)，既实现了“宁滥勿缺”（Low 也会报），又不会让用户被海量无关信息淹没（High 排在最前面）。
2.  **防止跨界干扰**: 理论只跟理论比，不会出现“把一个具体的营销手段误判为某个高深理论”的笑话。
3.  **人工审核友好**: Excel 报表中新旧语境并列，审核员无需翻阅原文，直接看 Excel 就能判断是否真的重复。